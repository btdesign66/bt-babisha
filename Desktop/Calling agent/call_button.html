<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéØ VoiceBot - Real-Time Communication</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            text-align: center;
            max-width: 600px;
            width: 100%;
        }

        .logo {
            font-size: 4rem;
            margin-bottom: 20px;
        }

        h1 {
            color: #333;
            margin-bottom: 15px;
            font-size: 2.2rem;
        }

        .description {
            color: #666;
            margin-bottom: 30px;
            line-height: 1.6;
        }

        .call-button {
            background: linear-gradient(45deg, #ff6b6b, #ee5a24);
            color: white;
            border: none;
            padding: 20px 40px;
            font-size: 1.2rem;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin-bottom: 30px;
            font-weight: bold;
            box-shadow: 0 10px 20px rgba(255,107,107,0.3);
        }

        .call-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 15px 30px rgba(255,107,107,0.4);
        }

        .call-button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .loading {
            display: none;
            margin: 20px 0;
        }

        .spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #667eea;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 15px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .call-status {
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            font-weight: bold;
        }

        .disconnected {
            background: #f8f9fa;
            color: #6c757d;
            border: 2px solid #dee2e6;
        }

        .connecting {
            background: #fff3cd;
            color: #856404;
            border: 2px solid #ffeaa7;
        }

        .connected {
            background: #d4edda;
            color: #155724;
            border: 2px solid #c3e6cb;
        }

        .error {
            display: none;
            background: #f8d7da;
            color: #721c24;
            border: 2px solid #f5c6cb;
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
        }

        .call-controls {
            display: none;
            gap: 15px;
            justify-content: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }

        .control-btn {
            padding: 12px 24px;
            border: none;
            border-radius: 25px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s ease;
        }

        .control-btn.primary {
            background: #dc3545;
            color: white;
        }

        .control-btn.primary:hover {
            background: #c82333;
        }

        .control-btn:not(.primary) {
            background: #6c757d;
            color: white;
        }

        .control-btn:not(.primary):hover {
            background: #5a6268;
        }

        .voice-indicator {
            display: none;
            margin: 20px 0;
            padding: 15px;
            background: #e3f2fd;
            border-radius: 10px;
            border: 2px solid #2196f3;
        }

        .voice-indicator.recording {
            background: #ffebee;
            border-color: #f44336;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }

        .conversation-log {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 10px;
            padding: 15px;
            margin: 15px 0;
            text-align: left;
            display: none;
            max-height: 300px;
            overflow-y: auto;
        }

        .conversation-log h4 {
            color: #333;
            margin-bottom: 15px;
            text-align: center;
        }

        .message {
            margin: 10px 0;
            padding: 10px;
            border-radius: 8px;
            position: relative;
        }

        .user-message {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            margin-left: 20px;
        }

        .bot-message {
            background: #f3e5f5;
            border-left: 4px solid #9c27b0;
            margin-right: 20px;
        }

        .message-label {
            font-weight: bold;
            font-size: 0.9em;
            margin-bottom: 5px;
        }

        .user-message .message-label {
            color: #1976d2;
        }

        .bot-message .message-label {
            color: #7b1fa2;
        }

        .message-content {
            color: #333;
        }

        .features {
            margin-top: 30px;
            text-align: left;
        }

        .features h3 {
            color: #333;
            margin-bottom: 15px;
            text-align: center;
        }

        .feature-list {
            list-style: none;
            padding: 0;
        }

        .feature-list li {
            padding: 8px 0;
            color: #666;
            position: relative;
            padding-left: 25px;
        }

        .feature-list li:before {
            content: "‚úÖ";
            position: absolute;
            left: 0;
            color: #28a745;
        }

        .debug-info {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 8px;
            padding: 10px;
            margin: 10px 0;
            font-size: 0.9em;
            color: #856404;
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="logo">üéØ</div>
        <h1>VoiceBot Real-Time Communication</h1>
        <p class="description">
            Experience true two-way voice communication with our AI assistant. 
            Speak naturally and get instant, continuous responses.
        </p>
        
        <button class="call-button" onclick="startCall()" id="callBtn">
            üìû Start Real-Time Call
        </button>
        
        <div class="loading" id="loading">
            <div class="spinner"></div>
            <p>Initializing real-time communication...</p>
        </div>
        
        <div id="callStatus" class="call-status disconnected">
            Status: Ready to start real-time call
        </div>
        
        <div class="error" id="error">
            Error: Could not connect to VoiceBot
        </div>

        <div class="voice-indicator" id="voiceIndicator">
            üé§ Real-time voice communication active - Speak now!
        </div>

        <div class="conversation-log" id="conversationLog">
            <h4>üí¨ Real-Time Conversation</h4>
            <div id="messages"></div>
        </div>
        
        <div class="call-controls" id="callControls">
            <button class="control-btn primary" onclick="endCall()">
                üö´ End Call
            </button>
            <button class="control-btn" onclick="muteToggle()" id="muteBtn">
                üîá Mute
            </button>
            <button class="control-btn" onclick="testRealTime()" style="background: #17a2b8;">
                üß™ Test Real-Time
            </button>
            <button class="control-btn" onclick="manualVoiceTest()" style="background: #28a745;">
                üé§ Manual Test
            </button>
            <button class="control-btn" onclick="simpleVoiceTest()" style="background: #fd7e14;">
                üéØ Simple Test
            </button>
            <button class="control-btn" onclick="testAudioRecording()" style="background: #e83e8c;">
                üéµ Test Audio
            </button>
            <button class="control-btn" onclick="testMicrophone()" style="background: #20c997;">
                üé§ Test Mic
            </button>
            <button class="control-btn" onclick="toggleDebug()" style="background: #6f42c1;">
                üêõ Debug
            </button>
        </div>

        <div class="debug-info" id="debugInfo">
            <strong>Debug Info:</strong><br>
            <span id="debugContent">No debug information available</span>
        </div>

        <div class="features">
            <h3>üéØ Real-Time Features:</h3>
            <ul class="feature-list">
                <li>Continuous two-way voice communication</li>
                <li>Real-time speech processing</li>
                <li>Instant AI responses</li>
                <li>Natural conversation flow</li>
                <li>Live conversation logging</li>
            </ul>
        </div>
    </div>

    <script>
        let currentSessionId = null;
        let isCallActive = false;
        let isMuted = false;
        let mediaRecorder = null;
        let audioChunks = [];
        let conversationCount = 0;
        let debugMode = false;
        let currentStream = null; // Store the current audio stream

        async function startCall() {
            try {
                // Update UI
                document.getElementById('callBtn').disabled = true;
                document.getElementById('loading').style.display = 'block';
                document.getElementById('callStatus').className = 'call-status connecting';
                document.getElementById('callStatus').textContent = 'Status: Initializing real-time communication...';
                document.getElementById('error').style.display = 'none';

                // Get microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                
                // Store the stream globally
                currentStream = stream;
                
                // Initialize call with backend
                const response = await fetch('/webrtc/call', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        caller_info: {
                            name: 'Real-Time User',
                            location: 'Browser',
                            browser: navigator.userAgent
                        }
                    })
                });

                const result = await response.json();
                
                if (result.status === 'connected') {
                    currentSessionId = result.session_id;
                    isCallActive = true;
                    
                    // Update UI
                    document.getElementById('loading').style.display = 'none';
                    document.getElementById('callStatus').className = 'call-status connected';
                    document.getElementById('callStatus').textContent = 'Status: Real-time communication active!';
                    document.getElementById('callControls').style.display = 'flex';
                    document.getElementById('voiceIndicator').style.display = 'block';
                    document.getElementById('voiceIndicator').className = 'voice-indicator recording';
                    document.getElementById('voiceIndicator').textContent = 'üé§ Real-time active - Speak naturally!';
                    document.getElementById('conversationLog').style.display = 'block';
                    
                    // Start real-time recording
                    startRealTimeRecording();
                    
                    // Add initial bot message
                    addMessage('AI Assistant', 'Hello! I\'m ready for real-time conversation. Please speak naturally and I\'ll respond immediately.', 'bot');
                    
                    console.log('Real-time call connected:', result);
                } else {
                    throw new Error(result.error || 'Failed to connect');
                }
                
            } catch (error) {
                console.error('Error starting call:', error);
                document.getElementById('loading').style.display = 'none';
                document.getElementById('error').style.display = 'block';
                document.getElementById('error').textContent = `Error: ${error.message}`;
                document.getElementById('callBtn').disabled = false;
                document.getElementById('callStatus').className = 'call-status disconnected';
                document.getElementById('callStatus').textContent = 'Status: Connection failed';
            }
        }

        function startRealTimeRecording() {
            if (!currentStream) {
                console.error('‚ùå No audio stream available');
                return;
            }
            
            console.log('üé§ Starting MediaRecorder with stream:', currentStream);
            console.log('üé§ Stream tracks:', currentStream.getTracks());
            
            // Check if stream has active audio tracks
            const audioTracks = currentStream.getAudioTracks();
            if (audioTracks.length === 0) {
                console.error('‚ùå No audio tracks in stream');
                return;
            }
            
            console.log('üé§ Audio track state:', audioTracks[0].readyState);
            console.log('üé§ Audio track enabled:', audioTracks[0].enabled);
            
            mediaRecorder = new MediaRecorder(currentStream, {
                mimeType: 'audio/webm;codecs=opus' // Use better audio format
            });
            audioChunks = [];

            mediaRecorder.ondataavailable = (event) => {
                console.log(`üéµ ondataavailable triggered: size=${event.data.size}, type=${event.data.type}`);
                if (event.data.size > 0) {
                    audioChunks.push(event.data);
                    console.log(`üéµ Audio chunk received: ${event.data.size} bytes`);
                } else {
                    console.warn('‚ö†Ô∏è Audio chunk has 0 size - this might indicate no audio input');
                }
            };

            mediaRecorder.onstart = () => {
                console.log('üé§ MediaRecorder started successfully');
                // Add a visual indicator that recording is active
                document.getElementById('voiceIndicator').textContent = 'üé§ Recording... Speak now!';
            };

            mediaRecorder.onerror = (event) => {
                console.error('‚ùå MediaRecorder error:', event);
                addMessage('System', 'Audio recording error occurred', 'bot');
            };

            mediaRecorder.onstop = async () => {
                console.log(`üõë Recording stopped, processing ${audioChunks.length} chunks...`);
                const totalSize = audioChunks.reduce((sum, chunk) => sum + chunk.size, 0);
                console.log(`üéµ Total audio data: ${totalSize} bytes`);
                
                if (totalSize > 100) { // Only process if we have substantial audio data
                    await processAudioChunks();
                } else {
                    console.warn('‚ö†Ô∏è Insufficient audio data captured - not processing');
                    addMessage('System', 'No voice input detected. Please speak louder or check your microphone.', 'bot');
                }
                
                // Restart recording immediately for continuous conversation
                if (isCallActive && currentStream) {
                    console.log('üîÑ Restarting recording for continuous conversation...');
                    setTimeout(() => startRealTimeRecording(), 100); // Small delay to prevent rapid restart
                }
            };

            // Start recording in shorter chunks for real-time response
            mediaRecorder.start(2000); // Record in 2-second chunks for faster response
            console.log('üé§ Recording started in 2-second chunks');
        }

        async function processAudioChunks() {
            if (audioChunks.length === 0) {
                console.log('‚ö†Ô∏è No audio chunks to process');
                return;
            }

            try {
                console.log(`üéµ Processing ${audioChunks.length} audio chunks...`);
                
                // Convert audio chunks to blob with proper MIME type
                let mimeType = 'audio/webm;codecs=opus';
                if (!MediaRecorder.isTypeSupported(mimeType)) {
                    mimeType = 'audio/webm';
                    if (!MediaRecorder.isTypeSupported(mimeType)) {
                        mimeType = 'audio/mp4';
                    }
                }
                
                const audioBlob = new Blob(audioChunks, { type: mimeType });
                console.log(`üì¶ Audio blob created: ${audioBlob.size} bytes, type: ${mimeType}`);
                
                // Check if we have enough audio data
                if (audioBlob.size < 100) {
                    console.warn('‚ö†Ô∏è Audio blob too small, might be silence');
                    addMessage('System', 'Audio input too quiet. Please speak louder.', 'bot');
                    return;
                }
                
                const reader = new FileReader();
                
                reader.onload = async () => {
                    try {
                        const audioData = reader.result.split(',')[1]; // Remove data:audio/...;base64, prefix
                        console.log(`üì§ Sending audio data (${audioData.length} chars) to backend...`);
                        
                        // Send to backend for processing
                        const response = await fetch('/webrtc/voice', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                            },
                            body: JSON.stringify({
                                session_id: currentSessionId,
                                audio_data: audioData
                            })
                        });

                        console.log(`üì• Backend response status: ${response.status}`);
                        
                        if (response.ok) {
                            const result = await response.json();
                            console.log('üéØ Backend result:', result);
                            
                            if (result.transcribed_text && result.response) {
                                console.log('‚úÖ Processing successful response');
                                
                                // Add user message to conversation log
                                addMessage('You', result.transcribed_text, 'user');
                                
                                // Add bot response to conversation log
                                addMessage('AI Assistant', result.response, 'bot');
                                
                                // Update voice indicator to show processing
                                document.getElementById('voiceIndicator').textContent = 'üé§ Processing response...';
                                
                                // Speak the response (if supported)
                                speakResponse(result.response);
                                
                                // Reset voice indicator after response
                                setTimeout(() => {
                                    if (isCallActive) {
                                        document.getElementById('voiceIndicator').textContent = 'üé§ Real-time active - Speak naturally!';
                                        console.log('üîÑ Voice indicator reset to active');
                                    }
                                }, 2000);
                                
                                // Update debug info if enabled
                                if (debugMode) {
                                    updateDebugInfo(`Processed: "${result.transcribed_text}" ‚Üí "${result.response}"`);
                                }
                            } else if (result.error) {
                                console.error('‚ùå Backend error:', result.error);
                                addMessage('System', `Error: ${result.error}`, 'bot');
                                document.getElementById('voiceIndicator').textContent = `‚ùå Error: ${result.error}`;
                            } else {
                                console.warn('‚ö†Ô∏è Response missing required fields:', result);
                                addMessage('System', 'Response incomplete', 'bot');
                            }
                        } else {
                            console.error('‚ùå HTTP error:', response.status, response.statusText);
                            const errorText = await response.text();
                            console.error('Error details:', errorText);
                            
                            if (response.status === 400) {
                                addMessage('System', 'Voice processing error. Please try speaking again.', 'bot');
                            } else {
                                addMessage('System', `Communication error: ${response.status}`, 'bot');
                            }
                        }
                    } catch (error) {
                        console.error('‚ùå Error in reader.onload:', error);
                        addMessage('System', `Processing error: ${error.message}`, 'bot');
                    }
                };
                
                reader.onerror = (error) => {
                    console.error('‚ùå FileReader error:', error);
                    addMessage('System', 'File reading error', 'bot');
                };
                
                reader.readAsDataURL(audioBlob);
                
            } catch (error) {
                console.error('‚ùå Error processing audio:', error);
                addMessage('System', `Processing error: ${error.message}`, 'bot');
                document.getElementById('voiceIndicator').textContent = `‚ùå Error: ${error.message}`;
            }
            
            // Clear chunks for next recording
            audioChunks = [];
            console.log('üßπ Audio chunks cleared for next recording');
        }

        function addMessage(sender, content, type) {
            const messagesDiv = document.getElementById('messages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}-message`;
            
            const label = document.createElement('div');
            label.className = 'message-label';
            label.textContent = sender;
            
            const messageContent = document.createElement('div');
            messageContent.className = 'message-content';
            messageContent.textContent = content;
            
            messageDiv.appendChild(label);
            messageDiv.appendChild(messageContent);
            messagesDiv.appendChild(messageDiv);
            
            // Auto-scroll to bottom
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
            
            // Increment conversation count
            conversationCount++;
        }

        function speakResponse(text) {
            if ('speechSynthesis' in window) {
                // Cancel any ongoing speech
                speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 0.9;
                utterance.pitch = 1;
                
                utterance.onend = () => {
                    console.log('Real-time response spoken');
                };
                
                utterance.onerror = (event) => {
                    console.error('Speech error:', event);
                };
                
                speechSynthesis.speak(utterance);
            }
        }

        async function testRealTime() {
            if (!currentSessionId) {
                alert('Please start a call first!');
                return;
            }
            
            console.log('üß™ Testing real-time communication...');
            
            // Simulate real-time voice input
            const testAudioData = 'real_time_test_' + Date.now();
            
            try {
                const response = await fetch('/webrtc/voice', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        session_id: currentSessionId,
                        audio_data: testAudioData
                    })
                });
                
                console.log('üß™ Real-time test response status:', response.status);
                
                if (response.ok) {
                    const result = await response.json();
                    console.log('üß™ Real-time test result:', result);
                    
                    if (result.transcribed_text && result.response) {
                        addMessage('Test User', result.transcribed_text, 'user');
                        addMessage('AI Assistant', result.response, 'bot');
                        document.getElementById('voiceIndicator').textContent = 'üß™ Real-time test successful!';
                        updateDebugInfo('Real-time test completed successfully');
                    } else {
                        addMessage('System', 'Test completed but no response generated', 'bot');
                    }
                } else {
                    const errorText = await response.text();
                    console.error('üß™ Real-time test failed:', response.status, errorText);
                    addMessage('System', `Test failed: ${response.status} - ${errorText}`, 'bot');
                }
            } catch (error) {
                console.error('üß™ Real-time test error:', error);
                addMessage('System', `Test error: ${error.message}`, 'bot');
            }
        }

        function manualVoiceTest() {
            if (!currentSessionId) {
                alert('Please start a call first!');
                return;
            }
            
            console.log('üé§ Manual voice test initiated...');
            addMessage('You', 'Manual voice test initiated...', 'user');
            
            // Simulate sending voice data directly
            const testAudioData = 'manual_test_' + Date.now();
            
            fetch('/webrtc/voice', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    session_id: currentSessionId,
                    audio_data: testAudioData
                })
            })
            .then(response => response.json())
            .then(result => {
                console.log('üéØ Manual test result:', result);
                if (result.transcribed_text && result.response) {
                    addMessage('AI Assistant', result.response, 'bot');
                    speakResponse(result.response);
                } else {
                    addMessage('System', 'Manual test failed - no response', 'bot');
                }
            })
            .catch(error => {
                console.error('‚ùå Manual test error:', error);
                addMessage('System', `Manual test error: ${error.message}`, 'bot');
            });
        }

        function simpleVoiceTest() {
            if (!currentSessionId) {
                alert('Please start a call first!');
                return;
            }

            console.log('üéØ Simple voice test initiated...');
            addMessage('You', 'Simple voice test initiated...', 'user');

            // Simulate sending a small audio chunk
            const testAudioData = 'simple_test_' + Date.now();

            fetch('/webrtc/voice', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    session_id: currentSessionId,
                    audio_data: testAudioData
                })
            })
            .then(response => response.json())
            .then(result => {
                console.log('üéØ Simple test result:', result);
                if (result.transcribed_text && result.response) {
                    addMessage('AI Assistant', result.response, 'bot');
                    speakResponse(result.response);
                } else {
                    addMessage('System', 'Simple test failed - no response', 'bot');
                }
            })
            .catch(error => {
                console.error('‚ùå Simple test error:', error);
                addMessage('System', `Simple test error: ${error.message}`, 'bot');
            });
        }

        function testAudioRecording() {
            if (!currentStream) {
                alert('No audio stream available. Please start a call first!');
                return;
            }

            console.log('üé§ Testing audio recording...');
            addMessage('System', 'Testing audio recording...', 'bot');

            // Create a test MediaRecorder
            const testRecorder = new MediaRecorder(currentStream);
            const testChunks = [];

            testRecorder.ondataavailable = (event) => {
                console.log(`üéµ Test recording - chunk: size=${event.data.size}, type=${event.data.type}`);
                testChunks.push(event.data);
            };

            testRecorder.onstop = () => {
                console.log(`üéµ Test recording stopped. Total chunks: ${testChunks.length}`);
                const totalSize = testChunks.reduce((sum, chunk) => sum + chunk.size, 0);
                console.log(`üéµ Total audio data: ${totalSize} bytes`);
                
                if (totalSize > 0) {
                    addMessage('System', `Audio recording test successful! Captured ${totalSize} bytes in ${testChunks.length} chunks.`, 'bot');
                } else {
                    addMessage('System', 'Audio recording test failed - no audio data captured.', 'bot');
                }
            };

            // Record for 2 seconds
            testRecorder.start();
            setTimeout(() => {
                testRecorder.stop();
            }, 2000);
        }

        function testMicrophone() {
            console.log('üé§ Testing microphone access...');
            addMessage('System', 'Testing microphone access...', 'bot');

            // Check if we can access the microphone
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                addMessage('System', '‚ùå MediaDevices API not supported in this browser', 'bot');
                return;
            }

            // Try to get microphone access
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    const tracks = stream.getTracks();
                    console.log('üé§ Microphone access successful');
                    console.log('üé§ Audio tracks:', tracks.length);
                    
                    tracks.forEach(track => {
                        console.log('üé§ Track:', track.kind, track.readyState, track.enabled);
                    });
                    
                    addMessage('System', `‚úÖ Microphone access successful! Found ${tracks.length} audio track(s)`, 'bot');
                    
                    // Stop the test stream
                    tracks.forEach(track => track.stop());
                })
                .catch(error => {
                    console.error('‚ùå Microphone access failed:', error);
                    addMessage('System', `‚ùå Microphone access failed: ${error.message}`, 'bot');
                });
        }

        function toggleDebug() {
            debugMode = !debugMode;
            const debugInfo = document.getElementById('debugInfo');
            debugInfo.style.display = debugMode ? 'block' : 'none';
            
            const debugBtn = document.getElementById('debugInfo').nextElementSibling;
            if (debugBtn) {
                debugBtn.style.background = debugMode ? '#dc3545' : '#6f42c1';
            }
        }

        function updateDebugInfo(info) {
            if (debugMode) {
                const debugContent = document.getElementById('debugContent');
                const timestamp = new Date().toLocaleTimeString();
                debugContent.innerHTML += `<br>[${timestamp}] ${info}`;
            }
        }

        async function endCall() {
            try {
                if (currentSessionId) {
                    await fetch('/webrtc/end', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            session_id: currentSessionId
                        })
                    });
                }

                // Stop recording
                if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                    mediaRecorder.stop();
                }

                // Stop all tracks in the stream
                if (currentStream) {
                    currentStream.getTracks().forEach(track => track.stop());
                    currentStream = null;
                }

                // Reset state
                currentSessionId = null;
                isCallActive = false;
                conversationCount = 0;
                
                // Update UI
                document.getElementById('callBtn').disabled = false;
                document.getElementById('callStatus').className = 'call-status disconnected';
                document.getElementById('callStatus').textContent = 'Status: Real-time call ended';
                document.getElementById('callControls').style.display = 'none';
                document.getElementById('voiceIndicator').style.display = 'none';
                document.getElementById('conversationLog').style.display = 'none';
                document.getElementById('loading').style.display = 'none';
                document.getElementById('error').style.display = 'none';
                document.getElementById('debugInfo').style.display = 'none';
                
                // Clear messages
                document.getElementById('messages').innerHTML = '';
                
                console.log('Real-time call ended');
                
            } catch (error) {
                console.error('Error ending call:', error);
            }
        }

        function muteToggle() {
            isMuted = !isMuted;
            const muteBtn = document.getElementById('muteBtn');
            
            if (isMuted) {
                muteBtn.textContent = 'üîä Unmute';
                muteBtn.style.background = '#28a745';
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.pause();
                }
            } else {
                muteBtn.textContent = 'üîá Mute';
                muteBtn.style.background = '#6c757d';
                if (mediaRecorder && mediaRecorder.state === 'paused') {
                    mediaRecorder.resume();
                }
            }
        }

        // Handle page unload
        window.addEventListener('beforeunload', () => {
            if (isCallActive) {
                endCall();
            }
        });
    </script>
</body>
</html>
